{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: To get files for this assignment # 2, run inverted index 5.0 and get files from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will use the index you created in Assignment 1 to rank documents \n",
    "and create a search engine. You will implement two different scoring functions and compare \n",
    "their results against a baseline ranking produced by expert analysts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this assignment, you will need the following two files:\n",
    "\n",
    "<font color=red>  </font> <font color=blue> topics.xml (\\\\sandata\\xeon\\Maryam Bashir\\Information Retrieval\\topics.xml) </font> contains the queries you will be testing. \n",
    "\n",
    "You should run the queries using the text stored in the <font color=green> query </font> elements. The <font color=green> description </font> elements are only there to clarify the information need which the query is trying to express</font> .\n",
    "\n",
    "\n",
    "<font color=red>  </font> <font color=blue> corpus.qrel (\\\\sandata\\xeon\\Maryam Bashir\\Information Retrieval\\corpus.qrel)</font> contains the relevance grades from expert assessors. While these grades are not necessarily entirely correct (and defining correctness unambiguously is quite difficult), they are fairly reliable and we will treat them as being correct here. \n",
    "\n",
    "The format here is:\n",
    "<font color=green> topic </font> <font color=green> 0 </font> <font color=green> docid </font> <font color=green> grade </font>\n",
    "\n",
    "<font color=red> o </font> <font color=green> topic </font> is the ID of the query for which the document was assessed.\n",
    "\n",
    "<font color=red> o </font> <font color=green> 0 </font> is part of the format and can be ignored.\n",
    "\n",
    "<font color=red> o </font> <font color=green> docid </font> is the name of one of the documents which you have indexed.\n",
    "\n",
    "<font color=red> o </font> <font color=green> grade </font> is a value in the set <font color=blue> {-2, 0, 1, 2, 3, 4} </font>, where a higher value means that the document is more relevant to the query. \n",
    "The value -2 indicates a spam document, and 0 indicates a non-spam document which is completely non- relevant. \n",
    "Most queries do not have any document with a grade of 4, and many queries do not have any document with a grade of 3.\n",
    "This is a consequence of the specific meaning assigned to these grades here and the manner in which the documents were collected.\n",
    "\n",
    "This <font color=green> QREL </font> does not have assessments for every  <font color=blue>(query, document) </font> pair. If an assessment is missing, we assume the correct grade for the pair is 0 (non-relevant).\n",
    "\n",
    "You will write a program which takes the name of a scoring function as a command line argument and which prints a ranked list of documents for all queries found in topics.xml using that scoring function. \n",
    "\n",
    "For example:\n",
    "\n",
    "<font color=red> $ </font>  <font color=green> ./query.py --score TF-IDF </font> \n",
    "\n",
    "<font color=blue> 202 clueweb12-0000tw-13-04988 1 0.73 run1 </font> \n",
    "\n",
    "<font color=blue> 202 clueweb12-0000tw-13-04901 2 0.33 run1 </font>  \n",
    "\n",
    "<font color=blue> 202 clueweb12-0000tw-13-04932 3 0.32 run1 </font>  ...\n",
    "\n",
    "<font color=blue> 214 clueweb12-0000tw-13-05088 1 0.73 run1 </font> \n",
    "\n",
    "<font color=blue> 214 clueweb12-0000tw-13-05001 2 0.33 run1 </font> \n",
    "\n",
    "<font color=blue> 214 clueweb12-0000tw-13-05032 3 0.32 run1 </font> ...\n",
    "\n",
    "<font color=blue> 250 clueweb12-0000tw-13-05032 500 0.002 run1 </font>\n",
    "\n",
    "\n",
    "The output should have one row for each document which your program ranks for each query it runs. \n",
    "These lines should have the format:\n",
    "\n",
    "<font color=green> topic </font> <font color=green> docid </font> <font color=green> rank </font> <font color=green> score </font> <font color=green> run </font>\n",
    "\n",
    "<font color=red>  </font> <font color=green> topic </font> is the ID of the query for which the document was ranked.\n",
    "\n",
    "<font color=red>  </font> <font color=green> docid </font> is the document identifier.\n",
    "\n",
    "<font color=red>  </font> <font color=green> rank </font> is the order in which to present the document to the user. The document with the highest score will be assigned a rank of 1, the second highest a rank of 2, and so on.\n",
    "\n",
    "<font color=red>  </font> <font color=green> score </font> is the actual score the document obtained for that query.\n",
    "\n",
    "<font color=red>  </font> <font color=green> run </font> is the name of the run. You can use any value here. It is meant to allow research teams to submit multiple runs for evaluation in competitions such as TREC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import os\n",
    "import operator\n",
    "import xml.dom.minidom\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "#from sets import Set\n",
    "#from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_path(mode):\n",
    "    \"\"\"\n",
    "    It takes only path of folder, no file name.\n",
    "    It only returns the folder which contain all the text file.\n",
    "    \n",
    "    Argument:\n",
    "    mode -- string specifying input or output for directory\n",
    "    \n",
    "    Returns:\n",
    "    dp -- directory path which contains all the txt files.\n",
    "    \"\"\"\n",
    "    if (mode == \"input\"):   \n",
    "        dp = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/\"\n",
    "    elif (mode == \"output\"):\n",
    "        dp = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/out/\"\n",
    "    else:\n",
    "        raise ValueError('Unspecified mode for I/O.')\n",
    "        dp = None\n",
    "\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function : read_stop_list\n",
    "def read_text_in_list_form(file_path):\n",
    "    \"\"\"\n",
    "    This function takes the path of stop words file and reads it and returns a list of words.\n",
    "    \n",
    "    Argument:\n",
    "    stop_file_path -- path should be like: \"(dir) + file_Name.extension\"\n",
    "        \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/stoplist.txt\".\n",
    "    \n",
    "    Returns:\n",
    "    lst -- list of words containg all the stop_words.\n",
    "    \"\"\"\n",
    "    \n",
    "    lst = [line.rstrip('\\n') for line in open(file_path)]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_word_file = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/stoplist.txt\"\n",
    "# stop_words = read_text_in_list_form(stop_word_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 2.0 using dictionary\n",
    "def xml_parser(file_name):\n",
    "    \"\"\"\n",
    "    It takes file name of xml file, which will contain the\n",
    "    queries with their unique topics-ids.\n",
    "    It returns the dictionary which contain topic-ids as keys and query of words values.\n",
    "    \n",
    "    Argument:\n",
    "    file_name -- this will be \"(dir)+topics.xml\"\n",
    "    \n",
    "    Returns:\n",
    "    queries -- directory with topic-ids as keys and query of words values.\n",
    "    \"\"\"\n",
    "    doc = xml.dom.minidom.parse(file_name)\n",
    "    qrys = doc.getElementsByTagName('query')\n",
    "    tpcs = doc.getElementsByTagName('topic')\n",
    "    queries = dict()\n",
    "    i = 0\n",
    "    for elem in qrys:\n",
    "        queries[tpcs[i].attributes['number'].value] = elem.firstChild.data\n",
    "        i = i + 1\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/topics.xml\"\n",
    "# qrys = xml_parser(file_name)\n",
    "# #print(qrys[str(202)])\n",
    "# print(qrys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running any scoring function, you should process the text of the query in exactly the same way that you processed the text of a document. That is:\n",
    "1. Split the query into tokens (it is most correct to use the regular expression, but for these queries it suffices to split on whitespace)\n",
    "2. Convert all tokens to lowercase\n",
    "3. Apply stop-wording to the query using the same list you used in assignment 1\n",
    "4. Apply the same stemming algorithm to the query which you used in your indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(tokenized_words_without_stop_words):\n",
    "    \"\"\"\n",
    "    This function takes in list of words which do not contain stop_words.\n",
    "    It uses the PorterStemmer() to reduce the words to their root word.\n",
    "    \n",
    "    Argument:\n",
    "    removed_all_stop_words -- list of all words which do not have stop_words.\n",
    "    \n",
    "    Returns:\n",
    "    stemmed_words -- list of words which are reduced to their origin word.\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = list()\n",
    "    for w in tokenized_words_without_stop_words:\n",
    "        stemmed_words.append(ps.stem(w))\n",
    "    stemmed_words.sort()\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing(query_string):\n",
    "    \"\"\"\n",
    "    This function takes in a query string and does the pre-processing on it.\n",
    "    It will first load stop words from directory, then split the query into\n",
    "    single-single terms. Then remove stop words from it.\n",
    "    \n",
    "    Argument:\n",
    "    query_string -- a string of query.\n",
    "    \n",
    "    Returns:\n",
    "    stemmed_tokens -- tokens of query after being stemmed.\n",
    "    \"\"\"\n",
    "    path_to_stop_words = get_directory_path(\"input\") +\"stoplist.txt\"\n",
    "    stop_words = read_text_in_list_form(path_to_stop_words)\n",
    "    #splited_query = list(re.split(query))\n",
    "    splited_query = list(query_string.split())\n",
    "    #splited_query.lower()\n",
    "    cleaned_tokens_from_stop_words =  list(set(splited_query) - set(stop_words))\n",
    "    stemmed_tokens = stem_words(cleaned_tokens_from_stop_words)\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(type(qrys[str(202)]))\n",
    "# x = query_processing(qrys[str(202)])\n",
    "# print((x))\n",
    "# print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Function 1: Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement BM25 scores. This should use the following scoring function for document d and query q:\n",
    "    \n",
    "Where k1,k2, and b are constants. For start, you can use the values suggested in the lecture on BM25 (k1 = 1.2, k2 varies from 0 to 1000, b = 0.75). Feel free to experiment with different values for these\n",
    "constants to learn their effect and try to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_documents_length(docid_hashed_file):\n",
    "    \"\"\"\n",
    "    It takes file name of a file which will contain doc-ids and\n",
    "    adjacent to it will be document name and length of each document.\n",
    "    \n",
    "    It only returns the dictionary which will have unique DOC_IDS as KEYS\n",
    "    and documents length as values.\n",
    "    \n",
    "    Argument:\n",
    "    docid_hashed_file -- this will be \"(dir)+docid_hashed.txt\"\n",
    "    \n",
    "    Returns:\n",
    "    doc_lengths -- is a dictionary as {doc-id : length_of_doc}.\n",
    "    \"\"\"\n",
    "    doc_lengths = dict()\n",
    "    file = open(docid_hashed_file, 'r' , encoding = \"utf-8\")\n",
    "    for each_line in file:\n",
    "        x = each_line.split()\n",
    "        doc_lengths[x[0]] = x[2]\n",
    "    return doc_lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docid_hashed_file = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/docid_hashed.txt\"\n",
    "# all_doc_lengths = get_all_documents_length(docid_hashed_file)\n",
    "# #c = int(all_doc_lengths[str(3058)])\n",
    "# #print(int(all_doc_lengths[str(3058)]))\n",
    "# print((all_doc_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_documents_name(docid_hashed_file):\n",
    "    \"\"\"\n",
    "    It takes file name of a file which will contain doc-ids and\n",
    "    adjacent to it will be document name and length of each document.\n",
    "    \n",
    "    It only returns the dictionary which will have unique DOC_IDS as KEYS\n",
    "    and document names as values.\n",
    "    \n",
    "    Argument:\n",
    "    docid_hashed_file -- this will be \"(dir)+docid_hashed.txt\"\n",
    "    \n",
    "    Returns:\n",
    "    doc_name-- it is a dictionary as {doc-id : doc-name}.\n",
    "    \"\"\"\n",
    "    doc_names = dict()\n",
    "    i = 0\n",
    "    file = open(docid_hashed_file,'r',encoding = \"utf-8\")\n",
    "    \n",
    "    for each_line in file:\n",
    "        x = each_line.split()\n",
    "        doc_names[x[0]] = x[1]\n",
    "    return doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docid_hashed_file = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/docid_hashed.txt\"\n",
    "# all_doc_names = get_all_documents_name(docid_hashed_file)\n",
    "# print((all_doc_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_vocablury(file_name):\n",
    "    \"\"\"\n",
    "    It takes file name of term-ids which will contain termids and\n",
    "    adjacent to termids will be terms.\n",
    "    It only returns the dictionary which will have unique TERMS as KEYS\n",
    "    and TERM_IDS will be the VALUES..\n",
    "    \n",
    "    Argument:\n",
    "    file_name -- this will be \"(dir)+termid_hashed.txt\"\n",
    "    \n",
    "    Returns:\n",
    "    vocablury -- it is a dictionary as {terms: term-ids}.\n",
    "    \"\"\"\n",
    "    vocablury = dict()\n",
    "    file = open(file_name,'r',encoding = \"utf-8\")\n",
    "    for each_line in file:\n",
    "        x = each_line.split()\n",
    "        #Interesting: making term as key and term_id as value (;\n",
    "        vocablury[x[1]] = x[0]\n",
    "    return vocablury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc_file = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/termid_hashed.txt\"\n",
    "# vocablury = get_all_vocablury(voc_file)\n",
    "# #print(vocablury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### version 2.0\n",
    "def get_document_postings(document_postings_file):\n",
    "    \"\"\"\n",
    "    It takes file name of a file which will contain termids and\n",
    "    adjacent to it will be list of documents in which this termid appears.\n",
    "    \n",
    "    It only returns the dictionary which will have unique TERMS_IDS as KEYS\n",
    "    and document list as values.\n",
    "    \n",
    "    Argument:\n",
    "    document_postings_file -- this will be \"(dir)+document_postings.txt\"\n",
    "    \n",
    "    Returns:\n",
    "    termid_with_doc_postings -- it is a dictionary as {terms-ids: list(documents)}.\n",
    "    \"\"\"\n",
    "    \n",
    "    termid_with_doc_postings = dict()\n",
    "    file = open(document_postings_file,'r',encoding = \"utf-8\")\n",
    "    for each_line in file:\n",
    "        x = (re.split(\"\\n\",each_line))\n",
    "        #print(\"x = \" , (x), \" len of x = \" ,len(x))\n",
    "        y = (re.split(\"\\t\", x[0]))\n",
    "        #print(\"y = \" , (y), \" len of y = \" ,len(y))\n",
    "        \n",
    "        temp_str = y[(len(y)-1)]\n",
    "        temp_str = temp_str.strip(\"[]\")\n",
    "        temp_str = temp_str.replace(\" \", \"\")\n",
    "        \n",
    "        lst = list()\n",
    "        lst = temp_str.split(\",\")\n",
    "        \n",
    "        current_term_id = y[0]\n",
    "        # create a key in dict_with_docid_and_its_positions\n",
    "        termid_with_doc_postings[current_term_id] = lst\n",
    "    return termid_with_doc_postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_postings_file = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/document_postings.txt\"\n",
    "# dict_termid_with_docs_postings = get_document_postings(doc_postings_file)\n",
    "# #print(dict_termid_with_docs_postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2.0\n",
    "def get_inverted_index(term_index_hashed_file):\n",
    "    \"\"\"\n",
    "    It takes file name of a inverted index file which will contain\n",
    "    term-ids and all of it's documents with all of it's positions.\n",
    "    \n",
    "    It returns the Nested dictionary which will have unique term-id\n",
    "    as key to outer dictionary and on a single term-id there may \n",
    "    have multiple documents, these documents will be used a keys to\n",
    "    inner dictionary, and on a single-document-id there may have\n",
    "    multiple positions on which that term appeared.\n",
    "    \n",
    "    Argument:\n",
    "    term_index_hashed_file -- this will be file name as \"(dir)+docid_hashed.txt\"\n",
    "    \n",
    "    Returns:\n",
    "    nested_dict_with_termid_and_its_docs_and_occurance -- it is a dictionary as {term-id : { doc-id : positions }}.\n",
    "    \"\"\"\n",
    "    nested_dict_with_termid_and_its_docs_and_occurance = dict()\n",
    "    doc_id_with_positions = dict()\n",
    "    file = open(term_index_hashed_file, 'r' , encoding = \"utf-8\")\n",
    "    length = 0\n",
    "    current_term_id = 0\n",
    "    for each_line in file:\n",
    "        x = (re.split(\"\\n\",each_line))\n",
    "        y = (re.split(\"\\t\", x[0]))\n",
    "        \n",
    "        if y[0] == '':\n",
    "            y = y[1:]\n",
    "        \n",
    "        # It means a New term_id aya hai, tou dict ki new key bnani\n",
    "        if (len(y) == 4):\n",
    "            # pick up last element, which will be list of positions in one document.\n",
    "            # and filter it with strip(), replace() methods.\n",
    "            temp_str = y[(len(y)-1)]\n",
    "            temp_str = temp_str.strip(\"[]\")\n",
    "            temp_str = temp_str.replace(\" \", \"\")\n",
    "            lst = list()\n",
    "            lst = temp_str.split(\",\")\n",
    "            \n",
    "            # reset length variable\n",
    "            doc_id_with_positions = dict()\n",
    "            length = 0\n",
    "            # new term_id now found\n",
    "            current_term_id = y[0]\n",
    "            current_document_id = y[1]\n",
    "            # create a key in dict_with_docid_and_its_positions\n",
    "            doc_id_with_positions[current_document_id] = lst\n",
    "            \n",
    "            #length = len(lst) #len((y[(len(y)-1)]))\n",
    "            nested_dict_with_termid_and_its_docs_and_occurance[current_term_id] = doc_id_with_positions\n",
    "            \n",
    "        elif (len(y) == 3):\n",
    "            # pick up last element, which will be list of positions in one document.\n",
    "            # and filter it with strip(), replace() methods.\n",
    "            temp_str = y[(len(y)-1)]\n",
    "            temp_str = temp_str.strip(\"[]\")\n",
    "            temp_str = temp_str.replace(\" \", \"\")\n",
    "            lst = list()\n",
    "            lst = temp_str.split(\",\")\n",
    "            current_document_id = y[0]\n",
    "            doc_id_with_positions[current_document_id] = lst\n",
    "\n",
    "            nested_dict_with_termid_and_its_docs_and_occurance.update({current_term_id:doc_id_with_positions})\n",
    "        else:\n",
    "            print(\"\\nI Don't know what to do.\\n\")   \n",
    "    return nested_dict_with_termid_and_its_docs_and_occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashed_term_id = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/term_index_hashed.txt\"\n",
    "# dict_term_id_with_frequencies = get_term_frequency(hashed_term_id)\n",
    "\n",
    "# print((dict_term_id_with_frequencies[str(583007)]))\n",
    "# #print((dict_term_id_with_frequencies[str(583007)][str(5256)]))\n",
    "# #print(len(dict_term_id_with_frequencies[str(583007)][str(5256)]))\n",
    "# #print(dict_term_id_with_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build version 2.3 : Final version\n",
    "# Changes Made: \n",
    "# finally removed unnecessary comments & print statements, and added proper comments &\n",
    "# replaced doc_id with doc_names as key of docs_score_for_each_query()\n",
    "def calculate_okapi_bm25(parameters):\n",
    "    k_1 = parameters['k1']\n",
    "    k_2 = parameters['k2']\n",
    "    b = parameters['b']\n",
    "    D = parameters['D']\n",
    "    \n",
    "    input_directory = get_directory_path(\"input\")\n",
    "    output_directory = get_directory_path(\"output\")\n",
    "    txt_extension = \".txt\"\n",
    "    xml_extension = \".xml\"\n",
    "    \n",
    "    queries_file_name = input_directory + \"topics\" + xml_extension\n",
    "    queries_dict = xml_parser(queries_file_name) \n",
    "    \n",
    "    doc_info_file = input_directory+ \"docid_hashed\" + txt_extension\n",
    "    all_doc_lengths = get_all_documents_length(doc_info_file)\n",
    "    \n",
    "    docid_hashed_file = input_directory + \"docid_hashed\" + txt_extension\n",
    "    all_doc_names = get_all_documents_name(docid_hashed_file)\n",
    "    \n",
    "    voc_file = input_directory + \"termid_hashed\" + txt_extension\n",
    "    vocablury = get_all_vocablury(voc_file)\n",
    "    \n",
    "    doc_postings_file = input_directory + \"document_postings\" + txt_extension\n",
    "    dict_termid_with_docs_postings = get_document_postings(doc_postings_file)\n",
    "    \n",
    "    inverted_index_file = input_directory + \"term_index_hashed\" + txt_extension\n",
    "    hashed_ii = get_inverted_index(inverted_index_file)\n",
    "    #hashed_ii\n",
    "    \n",
    "    avg_length = 0\n",
    "    for doc_id, length in all_doc_lengths.items():\n",
    "        avg_length += int(length)\n",
    "    avg_length /= len(all_doc_lengths) \n",
    "       \n",
    "    scores_dictionary = dict()\n",
    "    # Will run for number of times of queries in topics.xml\n",
    "    for query_id, query in queries_dict.items(): # run for 10 times\n",
    "        \n",
    "        # Split one query in terms\n",
    "        splitted_query = query_processing(query)\n",
    "        score_of_each_term_for_single_doc = 0\n",
    "        # Reset : docs_score_for_each_query.\n",
    "        docs_score_for_each_query = dict()\n",
    "        #scores_dictionary[query_id] = dict()    \n",
    "        # For loop for each term in single queries,\n",
    "        # i.e. if there is 3 word query, it will run for 3 times.\n",
    "        for i in range(0,len(splitted_query)): \n",
    "#             score_of_each_term_for_single_doc = 0\n",
    "            # Check If this splitted term (from query) exists in my vocablury.\n",
    "            if splitted_query[i] in vocablury: # if that term exists\n",
    "                # If YES, then get term_id of this splitted term (from query).\n",
    "                # Now, get value = term_id by passing term as key.\n",
    "                term_id = vocablury[splitted_query[i]]\n",
    "                \n",
    "                # Get list of documents in which this term exists\n",
    "                list_of_all_docs_in_which_term_exists = dict_termid_with_docs_postings[term_id]\n",
    "                \n",
    "                # Get it's document_frequency, i.e. In how many docs it is present.\n",
    "                df_i = len(list_of_all_docs_in_which_term_exists)\n",
    "                \n",
    "                # Now, run this loop for all docs in which it is present.\n",
    "                # i.e if it is present in 3 docs, it will run for 3 \n",
    "                for j in range(0,len(list_of_all_docs_in_which_term_exists)):\n",
    "                    # Now, pick one by one doc_id, and compute score.\n",
    "                    doc_id = list_of_all_docs_in_which_term_exists[j]\n",
    "                    doc_name = all_doc_names[doc_id]\n",
    "                    # Check IF that doc_id is present in my doc_postings file\n",
    "                    if doc_id in all_doc_lengths:\n",
    "                        # Get this term's frquency in this document\n",
    "                        tf_d_i = len(hashed_ii[str(term_id)][doc_id])\n",
    "                        tf_q_i = 1\n",
    "                        length_of_doc_id = int(all_doc_lengths[doc_id])\n",
    "                        capital_K = k_1 * ((1-b) + (b * (length_of_doc_id/avg_length)))\n",
    "                        a = float(D + 0.5)\n",
    "                        b = float(df_i + 0.5)\n",
    "                        c = float(math.log(a/b))\n",
    "                        d = float((1+k_1) * tf_d_i)\n",
    "                        e = float(capital_K + tf_d_i)\n",
    "                        f = float((1+k_2) * tf_q_i)\n",
    "                        g = float(k_2+tf_q_i)\n",
    "                        score_of_each_term_for_single_doc = c * (d/e) * (f/g)\n",
    "                        \n",
    "                        # Check IF already a term might have calculated score for this document (for same query).\n",
    "                        # Or we can say, multiple term words of single query might present in same document.\n",
    "                        # If YES: Else NO\n",
    "                        if doc_name in docs_score_for_each_query:\n",
    "                            prev_score = docs_score_for_each_query[doc_name]\n",
    "                            new_score = prev_score + score_of_each_term_for_single_doc\n",
    "                            docs_score_for_each_query[doc_name] = new_score\n",
    "                            sorted_docs_score_for_each_query = sorted(docs_score_for_each_query.items(), key=operator.itemgetter(1), reverse=True)\n",
    "                            scores_dictionary[query_id] = sorted_docs_score_for_each_query\n",
    "                        # Or maybe we found new document. Let's create a new key of doc_id on same query_id\n",
    "                        else:\n",
    "                            docs_score_for_each_query[doc_name] = dict()\n",
    "                            docs_score_for_each_query[doc_name] = score_of_each_term_for_single_doc\n",
    "                            sorted_docs_score_for_each_query = sorted(docs_score_for_each_query.items(), key=operator.itemgetter(1),reverse=True)\n",
    "                            scores_dictionary[query_id] = sorted_docs_score_for_each_query\n",
    "                            #scores_dictionary[query_id] = dict()\n",
    "                            scores_dictionary[query_id] = sorted_docs_score_for_each_query\n",
    "                    # Or maybe there is a document which is not in my possession.\n",
    "                    else:\n",
    "                        docs_score_for_each_query[doc_name] = 0\n",
    "                        scores_dictionary[query_id] = docs_score_for_each_query\n",
    "            # If this term is not in my Vocablury\n",
    "            else: \n",
    "                print(\"Terms of Queries which are not in my collection = \", splitted_query[i])\n",
    "\n",
    "    return scores_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms of Queries which are not in my collection =  uss\n",
      "Terms of Queries which are not in my collection =  vinson\n",
      "Terms of Queries which are not in my collection =  gain\n",
      "Terms of Queries which are not in my collection =  2008\n",
      "Terms of Queries which are not in my collection =  dog\n",
      "Terms of Queries which are not in my collection =  world'\n",
      "Terms of Queries which are not in my collection =  war\n"
     ]
    }
   ],
   "source": [
    "parameters = dict()\n",
    "parameters['k1'] = 1.2 \n",
    "parameters['k2'] = 500\n",
    "parameters['b'] = 0.75\n",
    "parameters['D'] = 17\n",
    "\n",
    "okapi_bmi25_score = calculate_okapi_bm25(parameters)\n",
    "#print(okapi_bmi25_score[str(214)])\n",
    "#a = (okapi_bmi25_score[str(214)])[0]\n",
    "#print(a[1])\n",
    "#print((okapi_bmi25_score[str(214)])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## version v3.0\n",
    "def dirichlet_smoothing():\n",
    "    \n",
    "    input_directory = get_directory_path(\"input\")\n",
    "    output_directory = get_directory_path(\"output\")\n",
    "    txt_extension = \".txt\"\n",
    "    xml_extension = \".xml\"\n",
    "    \n",
    "    queries_file_name = input_directory + \"topics\" + xml_extension\n",
    "    queries_dict = xml_parser(queries_file_name) \n",
    "    \n",
    "    doc_info_file = input_directory+ \"docid_hashed\" + txt_extension\n",
    "    all_doc_lengths = get_all_documents_length(doc_info_file)\n",
    "    \n",
    "    docid_hashed_file = input_directory + \"docid_hashed\" + txt_extension\n",
    "    all_doc_names = get_all_documents_name(docid_hashed_file)\n",
    "    \n",
    "    voc_file = input_directory + \"termid_hashed\" + txt_extension\n",
    "    vocablury = get_all_vocablury(voc_file)\n",
    "    \n",
    "    doc_postings_file = input_directory + \"document_postings\" + txt_extension\n",
    "    dict_termid_with_docs_postings = get_document_postings(doc_postings_file)\n",
    "    \n",
    "    inverted_index_file = input_directory + \"term_index_hashed\" + txt_extension\n",
    "    hashed_ii = get_inverted_index(inverted_index_file)\n",
    "    \n",
    "    mu = 0\n",
    "    total_length_of_collection = 0\n",
    "    for doc_id, length in all_doc_lengths.items():\n",
    "        total_length_of_collection += int(length)\n",
    "    mu = total_length_of_collection/len(all_doc_lengths) \n",
    "    \n",
    "    scores_dictionary = dict()\n",
    "    # Will run for number of times of queries in topics.xml\n",
    "    for query_id, query in queries_dict.items(): # run for 10 times\n",
    "        # Split one query in terms\n",
    "        splitted_query = query_processing(query)\n",
    "        score_of_each_term_for_single_doc = 0\n",
    "        # Reset : docs_score_for_each_query.\n",
    "        docs_score_for_each_query = dict()\n",
    "        \n",
    "        # For loop for each term in single queries,\n",
    "        # i.e. if there is 3 word query, it will run for 3 times.\n",
    "        for i in range(0,len(splitted_query)):            \n",
    "            # Check If this splitted term (from query) exists in my vocablury.\n",
    "            if splitted_query[i] in vocablury: # if that term exists\n",
    "                # If YES, then get term_id of this splitted term (from query).\n",
    "                # Now, get value = term_id by passing term as key.\n",
    "                term_id = vocablury[splitted_query[i]]\n",
    "                \n",
    "                # Get list of documents in which this term exists.\n",
    "                list_of_all_docs_in_which_term_exists = dict_termid_with_docs_postings[(term_id)]\n",
    "                \n",
    "                # Count the number of times each word occurs in Corpora, divide by total length.\n",
    "                # Basically add-up all lengths of documents.\n",
    "                sum_of_term_in_whole_corpora = 0\n",
    "                for d_idx, positinos in hashed_ii[term_id].items():\n",
    "                    sum_of_term_in_whole_corpora += len(positinos) # len(hashed_ii[term_id][positinos]) #\n",
    "                prob_of_term_occuring_in_whole_corpora = sum_of_term_in_whole_corpora/total_length_of_collection\n",
    "                \n",
    "                # Now, run this loop for all docs in which it is present.\n",
    "                # i.e if it is present in 3 docs, it will run for 3.\n",
    "                for j in range(0,len(list_of_all_docs_in_which_term_exists)):\n",
    "                    # Now, pick one by one doc_id, and compute score.\n",
    "                    doc_id = list_of_all_docs_in_which_term_exists[j]\n",
    "                    doc_name = all_doc_names[doc_id]\n",
    "                    # Check IF that doc_id is present in my doc_postings file.\n",
    "                    if doc_id in all_doc_lengths:\n",
    "                        N = int(all_doc_lengths[(doc_id)]) # doc length\n",
    "                        lamdba = N/(N+mu)\n",
    "                        one_minus_lamdba = 1 - lamdba\n",
    "                        \n",
    "                        # Count the number of times word occurs in document, divide by document length.\n",
    "                        count_of_term_in_single_doc = len(hashed_ii[term_id][doc_id])\n",
    "                        prob_occuring_in_single_doc = count_of_term_in_single_doc / N\n",
    "                        \n",
    "                        score_of_each_term_for_single_doc = (lamdba * prob_occuring_in_single_doc) + (one_minus_lamdba * prob_of_term_occuring_in_whole_corpora)\n",
    "                                                \n",
    "                        # Check IF already a term might have calculated score for this document (for same query).\n",
    "                        # Or we can say, multiple term words of single query might present in same document.\n",
    "                        # If YES: Else NO\n",
    "                        if doc_name in docs_score_for_each_query:\n",
    "                            prev_score = docs_score_for_each_query[doc_name]\n",
    "                            new_score = prev_score + score_of_each_term_for_single_doc\n",
    "                            docs_score_for_each_query.update({doc_name : new_score})\n",
    "                            sorted_docs_score_for_each_query = sorted(docs_score_for_each_query.items(), key=operator.itemgetter(1), reverse=True)\n",
    "                            scores_dictionary[query_id] = sorted_docs_score_for_each_query\n",
    "                        # Or maybe we found new document. Let's create a new key of doc_id on same query_id.\n",
    "                        else:\n",
    "                            docs_score_for_each_query[doc_name] = dict()\n",
    "                            docs_score_for_each_query[doc_name] = score_of_each_term_for_single_doc\n",
    "                            sorted_docs_score_for_each_query = sorted(docs_score_for_each_query.items(), key=operator.itemgetter(1),reverse=True)\n",
    "                            scores_dictionary[query_id] = sorted_docs_score_for_each_query\n",
    "                            #scores_dictionary[query_id] = dict()\n",
    "                            scores_dictionary[query_id] = sorted_docs_score_for_each_query\n",
    "                    # Or maybe there is a document which is not in my possession.\n",
    "                    else:\n",
    "                        docs_score_for_each_query[doc_name] = 0\n",
    "                        scores_dictionary[query_id] = docs_score_for_each_query\n",
    "            # If this term is not in my Vocablury.\n",
    "            else: \n",
    "                print(\"Terms of Queries which are not in my collection = \", splitted_query[i])\n",
    "\n",
    "    return scores_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms of Queries which are not in my collection =  uss\n",
      "Terms of Queries which are not in my collection =  vinson\n",
      "Terms of Queries which are not in my collection =  gain\n",
      "Terms of Queries which are not in my collection =  2008\n",
      "Terms of Queries which are not in my collection =  dog\n",
      "Terms of Queries which are not in my collection =  world'\n",
      "Terms of Queries which are not in my collection =  war\n"
     ]
    }
   ],
   "source": [
    "dirichlet_score = dirichlet_smoothing()\n",
    "#print(dirichlet_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_socre(scores_dictionary):\n",
    "    for query_id , doc_score_list in scores_dictionary.items():\n",
    "                # term_id \n",
    "        q_id = str(query_id)\n",
    "        i = 1\n",
    "        for j in range(0, len(doc_score_list)):\n",
    "            doc_name = doc_score_list[j][0]\n",
    "            score = doc_score_list[j][1]\n",
    "            lne = q_id  + \"\\t\"+ doc_name + \"\\t\" + str(i)+\"\\t\"+ str(score) + (\" run 1\")\n",
    "            print(lne)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dirichlet Score :\n",
      "\n",
      "202\tclueweb12-1012wb-63-19337\t1\t0.00116860351879504 run 1\n",
      "214\tclueweb12-1905wb-14-19033\t1\t0.00179380664652568 run 1\n",
      "214\tclueweb12-0211wb-75-04122\t2\t0.001541457082589648 run 1\n",
      "214\tclueweb12-0200wb-25-11228\t3\t0.001483216237314598 run 1\n",
      "214\tclueweb12-0800tw-39-05237\t4\t0.0011936339522546418 run 1\n",
      "216\tclueweb12-0800tw-39-05237\t1\t0.005371352785145889 run 1\n",
      "216\tclueweb12-0001wb-96-10862\t2\t0.004246395806028834 run 1\n",
      "216\tclueweb12-1705wb-99-01272\t3\t0.003131922694981285 run 1\n",
      "216\tclueweb12-1302wb-14-07756\t4\t0.0018557366467645638 run 1\n",
      "216\tclueweb12-1905wb-44-08158\t5\t0.0015234814863880242 run 1\n",
      "216\tclueweb12-0200wb-25-11228\t6\t0.000897736143637783 run 1\n",
      "221\tclueweb12-0303wb-53-27200\t1\t0.006728928592145716 run 1\n",
      "221\tclueweb12-1905wb-14-19033\t2\t0.006136706948640484 run 1\n",
      "221\tclueweb12-0211wb-75-04122\t3\t0.005273405808859322 run 1\n",
      "221\tclueweb12-1905wb-44-08158\t4\t0.0014572431608928928 run 1\n",
      "221\tclueweb12-0200wb-25-11228\t5\t0.000858704137392662 run 1\n",
      "227\tclueweb12-1012wb-63-19337\t1\t0.0037005778095176266 run 1\n",
      "227\tclueweb12-1905wb-44-08158\t2\t0.00264953301980526 run 1\n",
      "227\tclueweb12-1202wb-26-10513\t3\t0.001666931258929989 run 1\n",
      "230\tclueweb12-1302wb-14-07756\t1\t0.001613684040664838 run 1\n",
      "230\tclueweb12-0303wb-53-27200\t2\t0.001160160102094089 run 1\n",
      "230\tclueweb12-0200wb-25-11228\t3\t0.00078064012490242 run 1\n",
      "234\tclueweb12-1505wb-68-30103\t1\t0.006584801566114967 run 1\n",
      "234\tclueweb12-1302wb-14-07756\t2\t0.0015329998386315962 run 1\n",
      "234\tclueweb12-1012wb-63-19337\t3\t0.0012335259365058755 run 1\n",
      "243\tclueweb12-1102wb-73-18046\t1\t0.003988975921090804 run 1\n",
      "243\tclueweb12-0200wb-25-11228\t2\t0.000741608118657299 run 1\n",
      "246\tclueweb12-1101wb-78-26737\t1\t0.007799514128628052 run 1\n",
      "246\tclueweb12-0211wb-75-04122\t2\t0.004867759208177835 run 1\n",
      "246\tclueweb12-1504wb-72-14179\t3\t0.001978595197409839 run 1\n",
      "246\tclueweb12-0200wb-25-11228\t4\t0.001639344262295082 run 1\n",
      "246\tclueweb12-0800tw-39-05237\t5\t0.001259946949602122 run 1\n",
      "246\tclueweb12-0001wb-96-10862\t6\t0.0011533420707732635 run 1\n",
      "246\tclueweb12-1118wb-77-23080\t7\t0.0009219563914626839 run 1\n",
      "250\tclueweb12-1118wb-77-23080\t1\t0.0017978149633522335 run 1\n",
      "250\tclueweb12-0800tw-39-05237\t2\t0.001326259946949602 run 1\n",
      "250\tclueweb12-1905wb-44-08158\t3\t0.00132476650990263 run 1\n",
      "250\tclueweb12-0001wb-96-10862\t4\t0.0009960681520314548 run 1\n",
      "250\tclueweb12-0200wb-25-11228\t5\t0.000702576112412178 run 1\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\nOkapi BM-25 Score :\\n\")\n",
    "# print_socre(okapi_bmi25_score)\n",
    "\n",
    "\n",
    "print(\"\\nDirichlet Score :\\n\")\n",
    "print_socre(dirichlet_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To evaluate your results, we will write a program that computes mean average precision of the \n",
    "rank list of documents for different queries. The input to program will be the <font color=blue> qrel file \n",
    "(relevance judgments) </font> and scoring file that has rank list of documents. \n",
    "\n",
    "The output should be following measures: \n",
    "    \n",
    "<font color=red>  </font> <font color=green> P@5  </font>\n",
    "\n",
    "<font color=red>  </font> <font color=green> P@10 </font>\n",
    "\n",
    "<font color=red>  </font> <font color=green> P@20 </font>\n",
    "\n",
    "<font color=red>  </font> <font color=green> P@30 </font>\n",
    "\n",
    "<font color=red>  </font> <font color=green> MAP </font>\n",
    "\n",
    "These measures should be computed for each query. Average for all queries should also be computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qrel_reader_and_parser(qrel_file):\n",
    "    nested_dict_with_topics_and_its_docs_and_grades = dict()\n",
    "    doc_id_with_grades = dict()\n",
    "    file = open(qrel_file, 'r' , encoding = \"utf-8\")\n",
    "    length = 0\n",
    "\n",
    "    current_topic_id = 0\n",
    "    for each_line in file:\n",
    "        x = (re.split(\"\\n\",each_line))\n",
    "        y = (re.split(\" \", x[0]))\n",
    "        #print(y)\n",
    "        \n",
    "        current_topic_id = y[0]\n",
    "        # If current_topic already is already in my dict\n",
    "        if current_topic_id in nested_dict_with_topics_and_its_docs_and_grades: \n",
    "            current_doc_name = y[2]\n",
    "            doc_id_with_grades[current_doc_name] = int()\n",
    "            \n",
    "            val = 0\n",
    "            if int(y[3]) > 0:\n",
    "                val = 1\n",
    "            \n",
    "            # name_of_doc                        # grade\n",
    "            doc_id_with_grades[current_doc_name] = val\n",
    "            nested_dict_with_topics_and_its_docs_and_grades.update({current_topic_id : doc_id_with_grades})\n",
    "        \n",
    "        # Current_topic pehle se mujood naaii hai\n",
    "        else:\n",
    "            # Now new topic found, thus reset.\n",
    "            nested_dict_with_topics_and_its_docs_and_grades[current_topic_id] = dict()\n",
    "            doc_id_with_grades = dict()\n",
    "\n",
    "            current_doc_name = y[2]\n",
    "            doc_id_with_grades[current_doc_name] = int()\n",
    "            \n",
    "            val = 0\n",
    "            if int(y[3]) > 0:\n",
    "                val = 1\n",
    "            \n",
    "            # name_of_doc                       # grade\n",
    "            doc_id_with_grades[current_doc_name] = val\n",
    "            nested_dict_with_topics_and_its_docs_and_grades.update({current_topic_id : doc_id_with_grades})\n",
    "            \n",
    "    return nested_dict_with_topics_and_its_docs_and_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_file_path = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/relevance judgements.qrel\"\n",
    "dict_for_qrel = qrel_reader_and_parser(qrel_file_path)\n",
    "#print(dict_for_qrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precison(qrel_file_path, precision_mode, score_algorithm):\n",
    "    \n",
    "    dict_for_qrel = qrel_reader_and_parser(qrel_file_path)\n",
    "    \n",
    "    if (score_algorithm == \"dirichlet\"):\n",
    "        dirichlet_score = dirichlet_smoothing()\n",
    "    elif (score_algorithm == \"bm25\"):\n",
    "        parameters = dict()\n",
    "        parameters['k1'] = 1.2 \n",
    "        parameters['k2'] = 500\n",
    "        parameters['b'] = 0.75\n",
    "        parameters['D'] = 17\n",
    "        # okapi_bmi25_score = calculate_okapi_bm25(parameters)\n",
    "        # Naming it as dirichlet_score, because then I would have to change \n",
    "        # dictionary name dirichley_socre everywhere in code.\n",
    "        dirichlet_score = calculate_okapi_bm25(parameters)\n",
    "    else: \n",
    "        raise ValueError('Unspecified Scoring algorithm.')\n",
    "        sys.exit(0)\n",
    "        \n",
    "    if precision_mode == \"p5\":\n",
    "        dict_for_precision = dict()\n",
    "        precision = 0\n",
    "        relevant = 0\n",
    "        #retrieved2 = 5\n",
    "        for query_id, zipi in dirichlet_score.items():\n",
    "            count = 0\n",
    "            retrieved = len(dirichlet_score[query_id])\n",
    "            for i in range(0,len(zipi)):\n",
    "                #print(zipi[i][0]) = Doc_name\n",
    "                #print(zipi[i][0]) = calculated_score\n",
    "                doc_name = zipi[i][0]\n",
    "                if(count == 5):\n",
    "                    break\n",
    "                # IF THAT FOLDER EXISTS IN QREL AND HAS SCORE 1\n",
    "                if doc_name in dict_for_qrel[query_id] and dict_for_qrel[query_id][doc_name] > 0:\n",
    "                    relevant+=1\n",
    "                count+=1\n",
    "                #retrieved2+=1\n",
    "                precision = float(relevant/retrieved)\n",
    "            dict_for_precision[query_id] = precision\n",
    "                \n",
    "    elif precision_mode == \"p10\":\n",
    "        dict_for_precision = dict()\n",
    "        precision = 0\n",
    "        relevant = 0\n",
    "        #retrieved2 = 10\n",
    "        for query_id, zipi in dirichlet_score.items():\n",
    "            count = 0\n",
    "            retrieved = len(dirichlet_score[query_id])\n",
    "            for i in range(0,len(zipi)):\n",
    "                #print(zipi[i][0]) = Doc_name\n",
    "                #print(zipi[i][0]) = calculated_score\n",
    "                doc_name = zipi[i][0]\n",
    "                if(count == 10):\n",
    "                    break\n",
    "                # IF THAT FOLDER EXISTS IN QREL AND HAS SCORE 1\n",
    "                if doc_name in dict_for_qrel[query_id] and dict_for_qrel[query_id][doc_name] > 0:\n",
    "                    relevant+=1\n",
    "                count+=1\n",
    "                #retrieved2+=1\n",
    "                precision = float(relevant/retrieved)\n",
    "            dict_for_precision[query_id] = precision\n",
    "        \n",
    "    elif precision_mode == \"p20\":\n",
    "        dict_for_precision = dict()\n",
    "        precision = 0\n",
    "        relevant = 0\n",
    "        #retrieved2 = 20\n",
    "        for query_id, zipi in dirichlet_score.items():\n",
    "            count = 0\n",
    "            retrieved = len(dirichlet_score[query_id])\n",
    "            for i in range(0,len(zipi)):\n",
    "                #print(zipi[i][0]) = Doc_name\n",
    "                #print(zipi[i][0]) = calculated_score\n",
    "                doc_name = zipi[i][0]\n",
    "                if(count == 20):\n",
    "                    break\n",
    "                # IF THAT FOLDER EXISTS IN QREL AND HAS SCORE 1\n",
    "                if doc_name in dict_for_qrel[query_id] and dict_for_qrel[query_id][doc_name] > 0:\n",
    "                    relevant+=1\n",
    "                count+=1\n",
    "                #retrieved2+=1\n",
    "                precision = float(relevant/retrieved)\n",
    "            dict_for_precision[query_id] = precision\n",
    "    \n",
    "    elif precision_mode == \"p30\":\n",
    "        dict_for_precision = dict()\n",
    "        precision = 0\n",
    "        relevant = 0\n",
    "        #retrieved2 = 30\n",
    "        for query_id, zipi in dirichlet_score.items():\n",
    "            count = 0\n",
    "            retrieved = len(dirichlet_score[query_id])\n",
    "            for i in range(0,len(zipi)):\n",
    "                #print(zipi[i][0]) = Doc_name\n",
    "                #print(zipi[i][0]) = calculated_score\n",
    "                doc_name = zipi[i][0]\n",
    "                if(count == 30):\n",
    "                    break\n",
    "                # IF THAT FOLDER EXISTS IN QREL AND HAS SCORE 1\n",
    "                if doc_name in dict_for_qrel[query_id] and dict_for_qrel[query_id][doc_name] > 0:\n",
    "                    relevant+=1\n",
    "                count+=1\n",
    "                #retrieved2+=1\n",
    "                precision = float(relevant/retrieved)\n",
    "            dict_for_precision[query_id] = precision\n",
    "        \n",
    "    elif precision_mode == \"map\":\n",
    "        print(\"TODO\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Unspecified mode for Precision.')\n",
    "        sys.exit(0)\n",
    "        \n",
    "    print(dict_for_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms of Queries which are not in my collection =  uss\n",
      "Terms of Queries which are not in my collection =  vinson\n",
      "Terms of Queries which are not in my collection =  gain\n",
      "Terms of Queries which are not in my collection =  2008\n",
      "Terms of Queries which are not in my collection =  dog\n",
      "Terms of Queries which are not in my collection =  world'\n",
      "Terms of Queries which are not in my collection =  war\n",
      "{'202': 0.0, '214': 0.0, '216': 0.16666666666666666, '221': 0.4, '227': 0.6666666666666666, '230': 0.6666666666666666, '234': 0.6666666666666666, '243': 1.5, '246': 0.42857142857142855, '250': 0.6}\n"
     ]
    }
   ],
   "source": [
    "qrel_file_path = \"/Users/imbilalbutt/Documents/Semesters/Semester 9/Information Retrieval/Assignment/hw2/input/relevance judgements.qrel\"\n",
    "i_mode = \"p30\"\n",
    "\n",
    "score_algorithm = \"dirichlet\"\n",
    "#score_algorithm = \"bm25\"\n",
    "\n",
    "calculate_precison(qrel_file_path, i_mode, score_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1 = ['1','2','3']\n",
    "ls2 = ['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(zip(ls1,ls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(s[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
